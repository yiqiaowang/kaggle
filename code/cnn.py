# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R2tiljfinSp0VmgqbC2gWrsR5rEaUg4r
"""


import torch

IMAGE_SIZE = 28

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from torch.autograd import Variable
from torch.utils.data import TensorDataset, DataLoader



class Trainer:
    def __init__(self, model, learning_rate=1e-4, momentum=0.9, CUDA=True):
        self.model = model
        self.criterion = nn.CrossEntropyLoss()
        self.learning_rate = learning_rate
        self.momentum = momentum

        self.cuda = CUDA and torch.cuda.is_available()
        self.model = model
        if self.cuda:
            self.model = self.model.cuda()


    def train(self, train_x, train_y, num_epochs, log=True, batch_size=100, num_steps_to_log=100):
        training_data = torch.FloatTensor(train_x.reshape(-1, 1, IMAGE_SIZE, IMAGE_SIZE).astype(np.float))
        training_y = Trainer.convert_to_y(train_y.astype(np.uint8))
        dataset = TensorDataset(training_data, training_y)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)
        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)#, momentum=self.momentum)

        for epoch in range(num_epochs):
            for batch, (inputs, labels) in enumerate(dataloader):
                if self.cuda:
                    inputs, labels = inputs.cuda(), labels.cuda()
                inputs, labels = Variable(inputs), Variable(labels)
            

                optimizer.zero_grad()
                outputs = self.model(inputs)
                               
                _, classes = torch.max(labels, 1)

                
                loss = self.criterion(outputs, classes)
                loss.backward()
                optimizer.step()

                if log and batch % (num_steps_to_log - 1) == 0:
                    print("epoch {}, batch {}, loss {}".format(epoch+1, batch+1, loss.data[0]))
       
            
            if log:
                print("Finished epoch {} with loss of {}".format(epoch+1, loss.data[0]))
        return self.model


    def test(self, test_x, test_y):
        test_x = torch.FloatTensor(test_x.reshape(-1, 1, IMAGE_SIZE, IMAGE_SIZE).astype(np.uint8))
        if self.cuda:
            test_x = test_x.cuda()
        test_x = Variable(test_x)
        output = self.model(test_x)
        output = output.data
        if self.cuda:
            output = output.cpu()
        output = output.numpy()
        labels = Trainer.convert_to_labels(output)
        test_y = test_y.astype(np.uint8)
        accuracy = accuracy_score(test_y, labels)
        precision = precision_score(test_y, labels, average='micro')
        recall = recall_score(test_y, labels, average='micro')
        f1 = f1_score(test_y, labels, average='micro')
        conf_matrix = confusion_matrix(test_y, labels)
        return accuracy, precision, recall, f1, conf_matrix


    def convert_to_y(labels):
        output = []
        for label in labels:
            y_vector = [0] * 10
            y_vector[int(label)] = 1
            output.append(y_vector)
        return torch.FloatTensor(output)


    def convert_to_labels(ys):
        output = []
        for y in ys:
            output.append(np.argmax(y))
        return np.array(output, dtype='int')

class View(nn.Module):
    def __init__(self):
        super(View, self).__init__()
        
    def forward(self, x):
        return x.view(x.size(0), -1) 

class ConvNet(nn.Module):
    def __init__(self, params):
        super(ConvNet, self).__init__()
        
        # Set convnet parameters
        self.size_conv_layers = params['size_conv_layers']
        self.size_conv_filters = params['size_conv_filters']
        self.pool_size = params['pool_size']
        self.size_hidden_layers = params['size_hidden_layers']
        self.dropout_p = params['dropout_p']
        self._image_size = params['image_size']
 

        # Assume that the input to the first conv layer is of 1 dim
        self._conv_tuples = zip([1] + self.size_conv_layers[:-1],
                                self.size_conv_layers)
                 
           
        # Define convnet structure
        self.conv_layers = [
            nn.Conv2d(*t, f)
            for t,f in zip(
                self._conv_tuples,
                self.size_conv_filters
            )
        ]
       
        self.pool = nn.MaxPool2d(self.pool_size)    
        
        
        self._infer_hidden_0()
        _hidden_in_dim = self.size_conv_layers[-1] * self._image_size**2
        
        
        self._hidden_tuples = zip([_hidden_in_dim] + self.size_hidden_layers[:-1],
                          self.size_hidden_layers)
        
        self.view = View()
        
        self.hidden_layers = [
            nn.Linear(*t)
            for t in self._hidden_tuples
        ]
               
        self.dropout = nn.Dropout2d(p=self.dropout_p)
    
    @staticmethod  
    def conv_out_size(layer, w_old):
        """
        We assume the kernel_size will always be (nxn)
        and the stride will always by (kxk)
        """
        kern_width = layer.kernel_size[0]
        padding_l = layer.padding[0]
        padding_r = layer.padding[1]
        stride = layer.stride[0]
       
        return (w_old - kern_width + padding_l + padding_r)/stride + 1
  
    @staticmethod  
    def pool_out_size(layer, w_old):

        kern_width = layer.kernel_size
        padding = layer.padding
        stride = layer.stride
       
        # Janky as fk
        _tmp = (w_old - kern_width + padding)/stride + 1
        return int(_tmp)
  
    def _infer_hidden_0(self):
        for layer in self.conv_layers:
            self._image_size = ConvNet.conv_out_size(
                layer,
                self._image_size
            )
            self._image_size = ConvNet.pool_out_size(
                self.pool,
                self._image_size
            )
        
  
    def construct(self):
        
        _seq_mod = []
        
        _seq_mod.append(self.conv_layers[0])
        _seq_mod.append(nn.ReLU())
        _seq_mod.append(self.pool)
        
        for conv in self.conv_layers[1:]:
            _seq_mod.append(conv)
            _seq_mod.append(nn.ReLU())
            _seq_mod.append(self.pool)
            
        _seq_mod.append(self.view)

        if len(self.hidden_layers) > 1:
          _seq_mod.append(self.hidden_layers[0])
          _seq_mod.append(nn.ReLU())
          _seq_mod.append(self.dropout)
        
        for hidden in self.hidden_layers[1:-1]:
          _seq_mod.append(hidden)
          _seq_mod.append(nn.ReLU())
          _seq_mod.append(self.dropout)

        # No need to add a relu to the output layer
        _seq_mod.append(self.hidden_layers[-1])
        
        # Dont need this layer since CrossEntropyLoss already 
        # contains a logsoftmax layer
        #_seq_mod.append(nn.Softmax(dim=1))
        
        #for model in _seq_mod:
        #    print(model)
               
        return _seq_mod

from itertools import product
from collections import OrderedDict

class Hyperparameter:
    def __init__(self, model_params, trainer_params, model_definition, x, y, test_x, test_y, log=True):
        """
        model_params and trainer_params to be of the form:
            {param_name: [value1, value2, ..., valuen]}
        model_definition is a function that takes the parameters and returns the model.
        """
        self.x = x
        self.y = y
        self.log = log
        self.test_x = test_x
        self.test_y = test_y
        self.model_definition = model_definition
        self.model_params = OrderedDict(Hyperparameter.replace_single_items(model_params))
        self.trainer_params = OrderedDict(Hyperparameter.replace_single_items(trainer_params))
        self.create_trainer_keys = {"model", "learning_rate", "momentum", "CUDA"}


    def replace_single_items(obj):
        for key in obj:
            if type(obj[key]) != list:
                obj[key] = [obj[key]]
        return obj


    def train(self):
        results = []
        if self.log:
            step = 1

        for model_values in product(*self.model_params.values()):
            model_params = {
                key: model_values[index] for index, key in enumerate(self.model_params)
            }

            for trainer_values in product(*self.trainer_params.values()):
                model = self.model_definition(model_params)

                trainer_params = {
                    key: trainer_values[index] for index, key in enumerate(self.trainer_params)
                }
                trainer_params["model"] = model
                
                create_trainer_params = {
                    key: value for key, value in trainer_params.items() if key in self.create_trainer_keys
                }
                            
            
                training_params = {
                    key: value for key, value in trainer_params.items() if key not in self.create_trainer_keys
                }
                if 'log' not in training_params:
                    training_params['log'] = False
                training_params["train_x"] = self.x
                training_params["train_y"] = self.y
                trainer = Trainer(**create_trainer_params)
                trainer.train(**training_params)
                accuracy, precision, recall, f1, conf_matrix = trainer.test(self.test_x, self.test_y)
                
                
                score_object = {
                    "test_accuracy": accuracy,
                    "test_precision": precision,
                    "test_recall": recall,
                    "test_f1": f1,
                    "test_confusion_matrix": conf_matrix
                }
                for index, model_key in enumerate(self.model_params):
                    score_object[model_key] = model_values[index]

                for index, trainer_key in enumerate(self.trainer_params):
                    score_object[trainer_key] = trainer_values[index]

                results.append(score_object)
                print("accuracy =", accuracy)

                if self.log:
                    print(step, score_object)
                    step += 1
        
        return sorted(results, key=lambda score_object: score_object['test_accuracy'], reverse=True)

import cv2


def rotate_and_slice(rectangle, image):
    rotation_matrix = cv2.getRotationMatrix2D(center=rectangle[0], angle=0, scale=1)

    new_size = image.shape[0]*3//2
    larger_image = np.zeros((new_size, new_size), dtype=np.uint8)
    rotation_matrix[0,2] += ((new_size // 2) - rectangle[0][0])
    rotation_matrix[1,2] += ((new_size // 2) - rectangle[0][1])

    image = cv2.warpAffine(src=image, M=rotation_matrix, dsize=(new_size,new_size))

    return image[new_size//2 - IMAGE_SIZE//2: new_size//2 + IMAGE_SIZE//2, new_size//2 - IMAGE_SIZE//2: new_size//2 + IMAGE_SIZE//2]



def preprocess(x):
    x = x.reshape(-1, 64, 64).astype(np.uint8)
    result = []
    for t in range(len(x)):
        image = x[t]

        for i in range(len(image)):
            for j in range(len(image[0])):
                image[i][j] = 255 if image[i][j] > 250 else 0



        _, contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour_sizes = []
        largest_box = None
        largest_rectangle = None
        largest_contour_area = 0.0

        for contour in contours:
            bounding_rectangle = cv2.minAreaRect(contour)
            square_area = max(bounding_rectangle[1])**2

            if square_area > largest_contour_area:
                box = cv2.boxPoints(bounding_rectangle)
                box = np.int0(box)
                largest_box = box
                largest_rectangle = bounding_rectangle
                largest_contour_area = square_area

        
        mask = np.zeros(image.shape, np.uint8)
        cv2.drawContours(mask, [largest_box], -1, 1, -1)
        for i in range(len(image)):
            for j in range(len(image[0])):
                image[i][j] = (image[i][j] & mask[i][j])


        # plt.imshow(image, cmap='gray')
        # plt.show()
        image = rotate_and_slice(largest_rectangle, image)
        result.append(image)

        # plt.imshow(image, cmap='gray')
        # plt.show()
    return np.array(result, dtype=np.uint8)

URL_ENDPOINT = "http://cs.mcgill.ca/~ksinha4/datasets/kaggle/"

x = np.loadtxt(URL_ENDPOINT+"train_x.csv", delimiter=",").astype(np.uint8)
y = np.loadtxt(URL_ENDPOINT+"train_y.csv", delimiter=",").astype(np.uint8)

processed_x = preprocess(x)

from sklearn.model_selection import KFold
from time import time

model_params = {
    'size_conv_layers': [[60,30]],
    'size_conv_filters': [[5,3]],
    'pool_size': 2,
    'dropout_p': [0.1,0.125,0.15,0.175,0.2,0.225,0.25,0.275,0.3,0.325],
    'size_hidden_layers': [[512,256,10]],
    'image_size': IMAGE_SIZE
}
trainer_params = {
    'learning_rate': [0.001],
    'num_epochs': [1],
    'batch_size': [200],
    'log': False
}


def model_definition(params):
  cnet_constructor = ConvNet(params)
  cnet_layers = cnet_constructor.construct()
  return nn.Sequential(*cnet_layers)

kf = KFold(n_splits=5, shuffle=True)
for train_index, valid_index in kf.split(processed_x):
  train_x = processed_x[train_index]  
  train_y = y[train_index]
  
  valid_x = processed_x[valid_index]
  valid_y = y[valid_index]
  start = time()
  hyper_search = Hyperparameter(model_params, trainer_params, model_definition, train_x, train_y, valid_x, valid_y)
  results = hyper_search.train()
  end = time()
  print()

test_x = np.loadtxt(URL_ENDPOINT+"test_x.csv", delimiter=",").astype(np.uint8)

params = {
    'size_conv_layers': [50, 25],
    'size_conv_filters': [5,3],
    'pool_size': 2,
    'dropout_p': 0.25,
    'size_hidden_layers': [512,256,10],
    'image_size': IMAGE_SIZE
}

cnet_constructor = ConvNet(params)
cnet_layers = cnet_constructor.construct()
cnet = nn.Sequential(*cnet_layers)

data = np.concatenate((train_x, valid_x), axis=0)
y = np.concatenate((train_y, valid_y), axis=0)

from time import time
trainer = Trainer(cnet, learning_rate=0.001)
start = time()
trainer.train(data, y, num_epochs=10, batch_size=250, log=False)
end = time()
print(trainer.test(valid_x, valid_y))
print("Took", (end-start), "seconds to train")

from google.colab import files

def write_solution(model, test_x, file_name):
  test_x = preprocess(test_x)
  test_x = torch.FloatTensor(test_x.reshape(-1, 1, IMAGE_SIZE, IMAGE_SIZE).astype(np.uint8))
  test_x = test_x.cuda()
  test_x = Variable(test_x)
  
  predicted_y = model(test_x)
  predicted_y = predicted_y.data
  predicted_y = predicted_y.cpu()
  predicted_y = predicted_y.numpy()
  predicted_labels = Trainer.convert_to_labels(predicted_y)
  
  with open(file_name, 'w') as f:
    f.write("Id,Label\n")
    for index, y in enumerate(predicted_labels):
      f.write("{},{}\n".format(index, y))
  files.download(file_name)

write_solution(trainer.model, test_x, "cnn.csv")