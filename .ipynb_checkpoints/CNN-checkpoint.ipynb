{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yUt7ECcYIC7I"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "#from os import path\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yH1ShT-oLch0"
   },
   "outputs": [],
   "source": [
    "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yvhoayjnhfF0"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NPkwDzAgnv-C"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, learning_rate=1e-4, momentum=0.9, CUDA=True):\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.cuda = CUDA and torch.cuda.is_available()\n",
    "        self.model = model\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "\n",
    "    def train(self, train_x, train_y, num_epochs, log=True, batch_size=100, num_steps_to_log=100):\n",
    "        training_data = torch.FloatTensor(train_x.reshape(-1, 1, IMAGE_SIZE, IMAGE_SIZE).astype(np.float))\n",
    "        training_y = Trainer.convert_to_y(train_y.astype(np.uint8))\n",
    "        dataset = TensorDataset(training_data, training_y)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch, (inputs, labels) in enumerate(dataloader):\n",
    "                \n",
    "                if self.cuda:\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                               \n",
    "                _, classes = torch.max(labels, 1)\n",
    "\n",
    "                \n",
    "                loss = self.criterion(outputs, classes)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if log and batch % (num_steps_to_log - 1) == 0:\n",
    "                    print(\"epoch {}, batch {}, loss {}\".format(epoch+1, batch+1, loss.data[0]))\n",
    "            \n",
    "            if log and epoch % 100 == 0:\n",
    "                print(\"Finished epoch {} with loss of {}\".format(epoch+1, loss.data[0]))\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def test(self, test_x, test_y):\n",
    "        test_x = torch.FloatTensor(test_x.reshape(-1, 1, IMAGE_SIZE, IMAGE_SIZE).astype(np.uint8))\n",
    "        if self.cuda:\n",
    "            test_x = test_x.cuda()\n",
    "        test_x = Variable(test_x)\n",
    "        output = self.model(test_x)\n",
    "        output = output.data\n",
    "        if self.cuda:\n",
    "            output = output.cpu()\n",
    "        output = output.numpy()\n",
    "        labels = Trainer.convert_to_labels(output)\n",
    "        accuracy = accuracy_score(test_y.astype(np.uint8), labels)\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def convert_to_y(labels):\n",
    "        output = []\n",
    "        for label in labels:\n",
    "            y_vector = [0] * 10\n",
    "            y_vector[int(label)] = 1\n",
    "            output.append(y_vector)\n",
    "        return torch.FloatTensor(output)\n",
    "\n",
    "\n",
    "    def convert_to_labels(ys):\n",
    "        output = []\n",
    "        for y in ys:\n",
    "            output.append(np.argmax(y))\n",
    "        return np.array(output, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1JEAdD2bZb06"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DvlouFGTVJTg"
   },
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(View, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1) \n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Set convnet parameters\n",
    "        self.size_conv_layers = params['size_conv_layers']\n",
    "        self.size_conv_filters = params['size_conv_filters']\n",
    "        self.pool_size = params['pool_size']\n",
    "        self.size_hidden_layers = params['size_hidden_layers']\n",
    "        self.dropout_p = params['dropout_p']\n",
    "        self._image_size = params['image_size']\n",
    " \n",
    "\n",
    "        # Assume that the input to the first conv layer is of 1 dim\n",
    "        self._conv_tuples = zip([1] + self.size_conv_layers[:-1],\n",
    "                                self.size_conv_layers)\n",
    "                 \n",
    "           \n",
    "        # Define convnet structure\n",
    "        self.conv_layers = [\n",
    "            nn.Conv2d(*t, f)\n",
    "            for t,f in zip(\n",
    "                self._conv_tuples,\n",
    "                self.size_conv_filters\n",
    "            )\n",
    "        ]\n",
    "       \n",
    "        self.pool = nn.MaxPool2d(self.pool_size)    \n",
    "        \n",
    "        \n",
    "        self._infer_hidden_0()\n",
    "        _hidden_in_dim = self.size_conv_layers[-1] * self._image_size**2\n",
    "        \n",
    "        \n",
    "        self._hidden_tuples = zip([_hidden_in_dim] + self.size_hidden_layers[:-1],\n",
    "                          self.size_hidden_layers)\n",
    "        \n",
    "        self.view = View()\n",
    "        \n",
    "        self.hidden_layers = [\n",
    "            nn.Linear(*t)\n",
    "            for t in self._hidden_tuples\n",
    "        ]\n",
    "               \n",
    "        self.dropout = nn.Dropout2d(p=self.dropout_p)\n",
    "    \n",
    "    @staticmethod  \n",
    "    def conv_out_size(layer, w_old):\n",
    "        \"\"\"\n",
    "        We assume the kernel_size will always be (nxn)\n",
    "        and the stride will always by (kxk)\n",
    "        \"\"\"\n",
    "        kern_width = layer.kernel_size[0]\n",
    "        padding_l = layer.padding[0]\n",
    "        padding_r = layer.padding[1]\n",
    "        stride = layer.stride[0]\n",
    "       \n",
    "        return (w_old - kern_width + padding_l + padding_r)/stride + 1\n",
    "  \n",
    "    @staticmethod  \n",
    "    def pool_out_size(layer, w_old):\n",
    "\n",
    "        kern_width = layer.kernel_size\n",
    "        padding = layer.padding\n",
    "        stride = layer.stride\n",
    "       \n",
    "        # Janky as fk\n",
    "        _tmp = (w_old - kern_width + padding)/stride + 1\n",
    "        return int(_tmp)\n",
    "  \n",
    "    def _infer_hidden_0(self):\n",
    "        for layer in self.conv_layers:\n",
    "            self._image_size = ConvNet.conv_out_size(\n",
    "                layer,\n",
    "                self._image_size\n",
    "            )\n",
    "            self._image_size = ConvNet.pool_out_size(\n",
    "                self.pool,\n",
    "                self._image_size\n",
    "            )\n",
    "        \n",
    "  \n",
    "    def construct(self):\n",
    "        \n",
    "        _seq_mod = []\n",
    "        \n",
    "        _seq_mod.append(self.conv_layers[0])\n",
    "        _seq_mod.append(nn.ReLU())\n",
    "        _seq_mod.append(self.pool)\n",
    "        \n",
    "        for conv in self.conv_layers[1:]:\n",
    "            _seq_mod.append(conv)\n",
    "            _seq_mod.append(nn.ReLU())\n",
    "            _seq_mod.append(self.pool)\n",
    "            \n",
    "        _seq_mod.append(self.view)\n",
    "\n",
    "        if len(self.hidden_layers) > 1:\n",
    "          _seq_mod.append(self.hidden_layers[0])\n",
    "          _seq_mod.append(nn.ReLU())\n",
    "          _seq_mod.append(self.dropout)\n",
    "        \n",
    "        for hidden in self.hidden_layers[1:-1]:\n",
    "          _seq_mod.append(hidden)\n",
    "          _seq_mod.append(nn.ReLU())\n",
    "          _seq_mod.append(self.dropout)\n",
    "\n",
    "        # No need to add a relu to the output layer\n",
    "        _seq_mod.append(self.hidden_layers[-1])\n",
    "        \n",
    "        # Dont need this layer since CrossEntropyLoss already \n",
    "        # contains a logsoftmax layer\n",
    "        #_seq_mod.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        #for model in _seq_mod:\n",
    "        #    print(model)\n",
    "               \n",
    "        return _seq_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "76LaqKt2OEFG"
   },
   "outputs": [],
   "source": [
    "URL_ENDPOINT = \"http://cs.mcgill.ca/~pbelan17/\"\n",
    "\n",
    "train_x = np.loadtxt(URL_ENDPOINT+\"train_x_30000.csv\", delimiter=\",\")\n",
    "train_y = np.loadtxt(URL_ENDPOINT+\"train_y_30000.csv\", delimiter=\",\")\n",
    "\n",
    "test_x = np.loadtxt(URL_ENDPOINT+\"test_x_10000.csv\", delimiter=\",\")\n",
    "test_y = np.loadtxt(URL_ENDPOINT+\"test_y_10000.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3ofbMm2gXeT8"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 1000\n",
    "\n",
    "\n",
    "TRAIN_X = train_x[:TRAIN_SIZE]\n",
    "TRAIN_Y = train_y[:TRAIN_SIZE]\n",
    "\n",
    "TEST_X = test_x[:TEST_SIZE]\n",
    "TEST_Y = test_y[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tOgeDkbDOAUq"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'size_conv_layers': [16,32,64],\n",
    "    'size_conv_filters': [3,3,3],\n",
    "    'pool_size': 2,\n",
    "    'dropout_p': 0.2,\n",
    "    'size_hidden_layers': [512,256,10],\n",
    "    'image_size': IMAGE_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BmLi5AlUoXTa"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Hyperparameter:\n",
    "    def __init__(self, model_params, trainer_params, model_definition, x, y, test_x, test_y, log=True):\n",
    "        \"\"\"\n",
    "        model_params and trainer_params to be of the form:\n",
    "            {param_name: [value1, value2, ..., valuen]}\n",
    "        model_definition is a function that takes the parameters and returns the model.\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.log = log\n",
    "        self.test_x = test_x\n",
    "        self.test_y = test_y\n",
    "        self.model_definition = model_definition\n",
    "        self.model_params = OrderedDict(Hyperparameter.replace_single_items(model_params))\n",
    "        self.trainer_params = OrderedDict(Hyperparameter.replace_single_items(trainer_params))\n",
    "        self.create_trainer_keys = {\"model\", \"learning_rate\", \"momentum\", \"CUDA\"}\n",
    "\n",
    "\n",
    "    def replace_single_items(obj):\n",
    "        for key in obj:\n",
    "            if type(obj[key]) != list:\n",
    "                obj[key] = [obj[key]]\n",
    "        return obj\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        results = []\n",
    "        if self.log:\n",
    "            step = 1\n",
    "\n",
    "        for model_values in product(*self.model_params.values()):\n",
    "            model_params = {\n",
    "                key: model_values[index] for index, key in enumerate(self.model_params)\n",
    "            }\n",
    "\n",
    "            for trainer_values in product(*self.trainer_params.values()):\n",
    "                model = self.model_definition(model_params)\n",
    "\n",
    "                trainer_params = {\n",
    "                    key: trainer_values[index] for index, key in enumerate(self.trainer_params)\n",
    "                }\n",
    "                trainer_params[\"model\"] = model\n",
    "                \n",
    "                create_trainer_params = {\n",
    "                    key: value for key, value in trainer_params.items() if key in self.create_trainer_keys\n",
    "                }\n",
    "                            \n",
    "            \n",
    "                training_params = {\n",
    "                    key: value for key, value in trainer_params.items() if key not in self.create_trainer_keys\n",
    "                }\n",
    "                if 'log' not in training_params:\n",
    "                    training_params['log'] = False\n",
    "                training_params[\"train_x\"] = self.x\n",
    "                training_params[\"train_y\"] = self.y\n",
    "                trainer = Trainer(**create_trainer_params)\n",
    "                trainer.train(**training_params)\n",
    "                test_score = trainer.test(self.test_x, self.test_y)\n",
    "                \n",
    "                score_object = {\"test_accuracy\": test_score}\n",
    "                for index, model_key in enumerate(self.model_params):\n",
    "                    score_object[model_key] = model_values[index]\n",
    "\n",
    "                for index, trainer_key in enumerate(self.trainer_params):\n",
    "                    score_object[trainer_key] = trainer_values[index]\n",
    "\n",
    "                results.append(score_object)\n",
    "\n",
    "                if self.log:\n",
    "                    print(step, score_object)\n",
    "                    step += 1\n",
    "        \n",
    "        return sorted(results, key=lambda score_object: score_object['test_accuracy'], reverse=True)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q8dLgoprunwR"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def rotate_and_slice(rectangle, image):\n",
    "    if rectangle[1][0] > rectangle[1][1]:\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center=rectangle[0], angle=rectangle[2]+90, scale=1)\n",
    "    else:\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center=rectangle[0], angle=rectangle[2], scale=1)\n",
    "\n",
    "    new_size = image.shape[0]*3//2\n",
    "    larger_image = np.zeros((new_size, new_size), dtype=np.uint8)\n",
    "    rotation_matrix[0,2] += ((new_size // 2) - rectangle[0][0])\n",
    "    rotation_matrix[1,2] += ((new_size // 2) - rectangle[0][1])\n",
    "\n",
    "    image = cv2.warpAffine(src=image, M=rotation_matrix, dsize=(new_size,new_size))\n",
    "\n",
    "    return image[new_size//2 - IMAGE_SIZE//2: new_size//2 + IMAGE_SIZE//2, new_size//2 - IMAGE_SIZE//2: new_size//2 + IMAGE_SIZE//2]\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    x = x.reshape(-1, 64, 64).astype(np.uint8)\n",
    "    result = []\n",
    "    for t in range(len(x)):\n",
    "        image = x[t]\n",
    "\n",
    "        for i in range(len(image)):\n",
    "            for j in range(len(image[0])):\n",
    "                image[i][j] = 255 if image[i][j] > 250 else 0\n",
    "\n",
    "\n",
    "\n",
    "        _, contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_sizes = []\n",
    "        largest_box = None\n",
    "        largest_rectangle = None\n",
    "        largest_contour_area = 0.0\n",
    "\n",
    "        for contour in contours:\n",
    "            bounding_rectangle = cv2.minAreaRect(contour)\n",
    "            square_area = max(bounding_rectangle[1])**2\n",
    "\n",
    "            if square_area > largest_contour_area:\n",
    "                box = cv2.boxPoints(bounding_rectangle)\n",
    "                box = np.int0(box)\n",
    "                largest_box = box\n",
    "                largest_rectangle = bounding_rectangle\n",
    "                largest_contour_area = square_area\n",
    "\n",
    "        \n",
    "        mask = np.zeros(image.shape, np.uint8)\n",
    "        cv2.drawContours(mask, [largest_box], -1, 1, -1)\n",
    "        for i in range(len(image)):\n",
    "            for j in range(len(image[0])):\n",
    "                image[i][j] = (image[i][j] & mask[i][j])\n",
    "\n",
    "\n",
    "        # plt.imshow(image, cmap='gray')\n",
    "        # plt.show()\n",
    "        image = rotate_and_slice(largest_rectangle, image)\n",
    "        result.append(image)\n",
    "\n",
    "        # plt.imshow(image, cmap='gray')\n",
    "        # plt.show()\n",
    "    return np.array(result, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aIorC_FELy-E"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "URL_ENDPOINT = \"http://cs.mcgill.ca/~ksinha4/datasets/kaggle/\"\n",
    "\n",
    "x = np.loadtxt(URL_ENDPOINT+\"train_x.csv\", delimiter=\",\").astype(np.uint8)\n",
    "y = np.loadtxt(URL_ENDPOINT+\"train_y.csv\", delimiter=\",\").astype(np.uint8)\n",
    "\n",
    "unprocessed_train_x, unprocessed_valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rg0qPAHSzqIn"
   },
   "outputs": [],
   "source": [
    "train_x, valid_x = preprocess(unprocessed_train_x), preprocess(unprocessed_valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 712975,
     "status": "ok",
     "timestamp": 1521585788194,
     "user": {
      "displayName": "Mathew Wright",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101002757614869681843"
     },
     "user_tz": 240
    },
    "id": "0rPUDeSLqtYo",
    "outputId": "39a65411-20dc-4f07-911c-25f12c3d84b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'test_accuracy': 0.9186, 'size_conv_layers': [30, 60, 120], 'size_conv_filters': [5, 5, 5], 'pool_size': 2, 'dropout_p': 0.2, 'size_hidden_layers': [512, 256, 10], 'image_size': 36, 'learning_rate': 0.001, 'num_epochs': 100, 'log': False}\n",
      "[{'test_accuracy': 0.9186, 'size_conv_layers': [30, 60, 120], 'size_conv_filters': [5, 5, 5], 'pool_size': 2, 'dropout_p': 0.2, 'size_hidden_layers': [512, 256, 10], 'image_size': 36, 'learning_rate': 0.001, 'num_epochs': 100, 'log': False}]\n",
      "Took 712.6835327148438 seconds to train\n"
     ]
    }
   ],
   "source": [
    "#model_params = {\n",
    "#    'size_conv_layers': [[16,32,64]],\n",
    "#    'size_conv_filters': [[5,5,5], [6,6,6], [7,7,7]],\n",
    "#    'pool_size': 2,\n",
    "#    'dropout_p': [0.4,0.5,0.6,0.7,0.8],\n",
    "#    'size_hidden_layers': [[512,256,10]],\n",
    "#    'image_size': 64\n",
    "#}\n",
    "model_params = {\n",
    "    'size_conv_layers': [[30,60,120]],\n",
    "    'size_conv_filters': [[5,5,5]],\n",
    "    'pool_size': 2,\n",
    "    'dropout_p': [0.2],\n",
    "    'size_hidden_layers': [[512, 256, 10]],\n",
    "    'image_size': IMAGE_SIZE\n",
    "}\n",
    "trainer_params = {\n",
    "    'learning_rate': 0.001,#[0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015],\n",
    "    'num_epochs': 100,\n",
    "    'log': False\n",
    "}\n",
    "\n",
    "def model_definition(params):\n",
    "  cnet_constructor = ConvNet(params)\n",
    "  cnet_layers = cnet_constructor.construct()\n",
    "  return nn.Sequential(*cnet_layers)\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "hyper_search = Hyperparameter(model_params, trainer_params, model_definition, train_x, train_y, valid_x, valid_y)\n",
    "results = hyper_search.train()\n",
    "end = time()\n",
    "print(results)\n",
    "print(\"Took {} seconds to train\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hCYwLIXZoBNU"
   },
   "outputs": [],
   "source": [
    "cnet_constructor = ConvNet(params)\n",
    "cnet_layers = cnet_constructor.construct()\n",
    "cnet = nn.Sequential(*cnet_layers)\n",
    "\n",
    "from time import time\n",
    "trainer = Trainer(cnet, learning_rate=0.005)\n",
    "start = time()\n",
    "trainer.train(TRAIN_X, TRAIN_Y, num_epochs=20, log=False)\n",
    "end = time()\n",
    "print(\"Train accuracy:\", trainer.test(TRAIN_X, TRAIN_Y))\n",
    "print(\"Test accuracy:\", trainer.test(TEST_X, TEST_Y))\n",
    "print(\"Took\", (end-start), \"seconds to train\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "CNN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
